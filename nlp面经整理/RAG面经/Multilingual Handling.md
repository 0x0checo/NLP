å¥½å˜ï¼ŒDay 3 å¼€è¯¾ï¼š**å¤šè¯­è¨€ RAGï¼ˆMultilingual RAGï¼‰** ğŸŒ
è¿™ä¸€å—æ˜¯ä»–ä»¬ JD é‡Œç›´æ¥ç‚¹åçš„é‡ç‚¹ï¼ˆâ€œMultilingual Handlingâ€ï¼‰ï¼Œä½ è¦åšåˆ°ï¼š

* èƒ½æ¸…æ¥šè®²å‡ºï¼š**å¤šè¯­è¨€æœ‰å“ªå‡ ç§å¤„ç†æ–¹æ¡ˆ**
* çŸ¥é“æ¯ç§æ–¹æ¡ˆçš„ **ä¼˜ç¼ºç‚¹ + åœ¨æŠ€æœ¯æ–‡æ¡£é‡Œçš„å‘**
* èƒ½è¯´å‡ºï¼š**ä½ ä¼šæ€ä¹ˆåœ¨è¿™ä¸ª thesis é‡Œè®¾è®¡å¯¹æ¯”å®éªŒ**

æˆ‘ä¼šè¾¹è®²æ¦‚å¿µï¼Œè¾¹ç»™ä½ â€œé¢è¯•å¯ä»¥ç›´æ¥èƒŒçš„è‹±æ–‡ç­”æ¡ˆâ€ã€‚

---

## ä¸€ã€å…ˆæŠŠåœºæ™¯è¯´æ¸…æ¥šï¼ˆä½ å¯ä»¥å¤è¿°ç»™é¢è¯•å®˜ï¼‰

ä»–ä»¬è¿™æ¬¡é¢˜ç›®çš„åœºæ™¯å¤§æ¦‚æ˜¯ï¼š

* æ–‡æ¡£æ˜¯å¤šè¯­è¨€çš„ï¼š**English / Swedish / German**
* æ–‡æ¡£ç±»å‹ï¼štechnical manuals, parts lists, price lists
* ç”¨æˆ·æŸ¥è¯¢ï¼š

  * å¯èƒ½æ˜¯è‹±æ–‡ï¼š

    > â€œFind part X-1234, what is its price and specs?â€
  * ä¹Ÿå¯èƒ½æ˜¯ç‘å…¸è¯­ / å¾·è¯­ï¼š

    > â€œHitta del X-1234, vad kostar den och vilka specifikationer har den?â€
* æœ‰æ—¶å€™è¿˜ä¼šæœ‰**äº¤å‰è¯­è¨€**ï¼š

  * ç”¨æˆ·ç”¨è‹±æ–‡é—®ï¼Œæ–‡æ¡£åªæœ‰å¾·æ–‡æ‰‹å†Œï¼›

ä½ åœ¨é¢è¯•é‡Œå¯ä»¥å…ˆç”¨ä¸€å¥è¯æ¡†ä½é—®é¢˜ï¼š

> So weâ€™re in a **multilingual, domain-specific technical documentation** setting, with manuals and parts lists in English, Swedish, and German, and queries that can be in any of these languages.
> That means the RAG system must support **monolingual and cross-lingual retrieval** reliably.

---

## äºŒã€ä¸¤æ¡ä¸»è·¯çº¿ï¼šMultilingual Embeddings vs Translate-then-Index

è¿™æ˜¯ Day 3 æœ€æ ¸å¿ƒçš„å¯¹æ¯”ã€‚
ä½ åªè¦æŠŠè¿™å¼ â€œå¯¹ç…§è¡¨â€è®²é¡ºï¼Œé¢è¯•å°±å¾ˆç¨³äº†ã€‚

### 2.1 æ–¹æ¡ˆ Aï¼šMultilingual Embeddings

**æ€è·¯ï¼š**

* æ–‡æ¡£ä¿ç•™åŸè¯­è¨€ï¼šEnglish / Swedish / German
* ç”¨ä¸€ä¸ª**å¤šè¯­è¨€ embedding æ¨¡å‹**ï¼ˆæ¯”å¦‚å¤šè¯­è¨€çš„ OpenAI/Cohereã€LaBSE ä¹‹ç±»ï¼‰
* æŠŠæ‰€æœ‰è¯­è¨€æ˜ å°„åˆ°**åŒä¸€ä¸ªå‘é‡ç©ºé—´**
* æŸ¥è¯¢ï¼ˆä»»ä½•è¯­è¨€ï¼‰åŒæ ·ç”¨è¿™ä¸ªæ¨¡å‹ç¼–ç ï¼Œç„¶ååœ¨ä¸€ä¸ªç»Ÿä¸€çš„å‘é‡åº“é‡Œæœ

ä½ å¯ä»¥è¿™ä¹ˆè¯´ï¼š

> One natural approach is to use **multilingual embeddings**:
> we keep documents in their original languages and use a multilingual encoder so that all texts live in a shared vector space.
> Then a Swedish query can directly retrieve a German manual if they are semantically related.

**ä¼˜ç‚¹ï¼š**

* ä¸éœ€è¦æå‰ç¿»è¯‘æ•´ä¸ªæ–‡æ¡£åº“ â†’ çœæˆæœ¬
* é¿å…ç¿»è¯‘æŠŠ**ä¸“æœ‰åè¯/æœ¯è¯­/æ•°å­—**æé”™
* å¤©ç„¶æ”¯æŒ**è·¨è¯­è¨€æ£€ç´¢**ï¼ˆEnglish â†’ German docï¼‰

**ç¼ºç‚¹ / é£é™©ï¼š**

* å¤šè¯­è¨€ embedding åœ¨æŸäº›è¯­è¨€ / ä¸“ä¸šé¢†åŸŸå¯èƒ½è¡¨è¾¾ä¸å¤Ÿå¥½
* ç‘å…¸è¯­ / å¾·è¯­æŠ€æœ¯æœ¯è¯­ã€ç¼©å†™ã€å¤åˆè¯ï¼ˆç‰¹åˆ«æ˜¯å¾·è¯­ï¼‰å¯èƒ½ embedding è¡¨ç¤ºä¸ç¨³å®š
* åµŒå…¥è´¨é‡ä¸å¤Ÿå¥½æ—¶ï¼Œ**ç›¸ä¼¼åº¦æ’åºä¼šå˜å·®**

ä½ å¯ä»¥å†åŠ ä¸€å¥ä»–ä»¬çˆ±å¬çš„ï¼š

> For this thesis, multilingual embeddings are a very attractive baseline, because Weaviate already integrates multilingual vectorizers, and it avoids the full translation cost upfront.

---

### 2.2 æ–¹æ¡ˆ Bï¼šTranslate-then-Indexï¼ˆå…ˆç¿»è¯‘å†å»ºåº“ï¼‰

**æ€è·¯ï¼š**

* æŠŠæ‰€æœ‰éè‹±æ–‡æ–‡æ¡£ï¼ˆç‘å…¸è¯­/å¾·è¯­ï¼‰ç¦»çº¿ç¿»è¯‘æˆè‹±æ–‡
* ç´¢å¼•ç»Ÿä¸€çš„è‹±æ–‡ç‰ˆæœ¬ï¼ˆä¹Ÿå¯ä»¥ä¿ç•™åŸæ–‡ä½œ metadataï¼‰
* æŸ¥è¯¢å¯ä»¥ï¼š

  * åŸæ ·ä¸¢ç»™ä¸€ä¸ªå¼ºå¤šè¯­è¨€ embeddingï¼ˆä¹Ÿè¡Œï¼‰
  * æˆ–è€… **å…ˆç¿»è¯‘æˆè‹±æ–‡å† embedding**

ä½ å¯ä»¥è¿™æ ·è¯´ï¼š

> The other straightforward option is **translate-then-index**:
> we translate non-English manuals into English offline, index the English versions, and optionally store the original text as metadata.
> Queries in other languages can also be translated to English before embedding.

**ä¼˜ç‚¹ï¼š**

* å¯ä»¥ç”¨æœ€å¼ºçš„**è‹±æ–‡ embedding æ¨¡å‹**ï¼ˆå¾ˆå¤šæ¨¡å‹è‹±è¯­è¡¨ç°æœ€å¥½ï¼‰
* ä¸‹æ¸¸å¤„ç†ç»Ÿä¸€åœ¨è‹±è¯­ä¸Šåšï¼Œæ¯”è¾ƒç®€å•
* æœ‰äº›è¯„ä¼°/è§„åˆ™åŒ¹é…å·¥ä½œåœ¨è‹±æ–‡ä¸Šæ›´æˆç†Ÿ

**ç¼ºç‚¹ï¼š**

* ç¿»è¯‘æ˜¯æœ‰å™ªå£°å’Œæˆæœ¬çš„ï¼š

  * æœ¯è¯­å¯èƒ½è¢«è¯¯ç¿»
  * å•ä½ã€æ•°å€¼ã€ç¼©å†™å¯èƒ½è¢«æä¹±
* å¯¹è¶…å¤§æ–‡æ¡£åº“ï¼Œ**ä¸€æ¬¡æ€§ç¿»è¯‘æˆæœ¬å¾ˆé«˜**
* å‡ºç° bug æ—¶å¾ˆéš¾åˆ¤æ–­æ˜¯â€œç¿»è¯‘é—®é¢˜â€è¿˜æ˜¯â€œretrieval é—®é¢˜â€

ä½ å¯ä»¥åŠ ä¸€å¥ï¼š

> In technical documentation, translation errors on part names, tolerances, or safety instructions can be quite problematic.
> So any translate-then-index approach must be evaluated carefully on domain-specific examples.

---

### 2.3 Hybridï¼šä¸¤ç§ä¸€èµ·ä¸Šï¼ˆå¯ä»¥å½“â€œæœªæ¥å·¥ä½œ/æ‰©å±•â€è¯´ï¼‰

ä½ å¯ä»¥æä¸€ä¸ªæ··åˆæ–¹æ¡ˆï¼ˆæ˜¾å¾—ä½ æƒ³å¾—è¿œï¼‰ï¼š

> There is also a hybrid option:
>
> * store both the **original** and the **English-translated** text as separate chunks,
> * index them with appropriate metadata (`language`, `is_translated`)
>   and let the system retrieve from both.
>
> This might combine the robustness of English embeddings with the fidelity of original-language text.

ä¸ç”¨ç»†è®²ï¼Œåªè¦è¡¨æ˜ä½ è„‘å­é‡Œæœ‰è¿™ä¸ªæ‰©å±•æ–¹å‘ã€‚

---

## ä¸‰ã€å¤šè¯­è¨€ RAG æ—¶ï¼ŒWeaviate / å‘é‡åº“æ€ä¹ˆå»ºæ¨¡ï¼Ÿ

ä½ å¯ä»¥ç»“åˆ Day2 çš„ chunkingï¼Œè®²ä¸€ä¸ª**schema + æµç¨‹**ã€‚

### 3.1 index é˜¶æ®µï¼šç®€åŒ–ä¼ªä»£ç 

```python
def index_chunk(chunk, embed):
    vec = embed(chunk["text"])  # multilingual embedding æˆ– è‹±æ–‡ embedding
    payload = {
        "text": chunk["text"],
        "language": chunk["language"],  # "en", "sv", "de"
        "doc_id": chunk["doc_id"],
        "part_number": chunk.get("part_number"),
        "section_title": chunk.get("section_title"),
        "is_translation": chunk.get("is_translation", False),
    }
    vector_db.insert(vector=vec, payload=payload)
```

ä½ å¯ä»¥åœ¨é¢è¯•è¿™æ ·è¯´ï¼š

> In the vector store schema, I would make sure to include a `language` field and possibly an `is_translation` flag, in addition to `doc_id`, `part_number`, `section_title`, etc.
> That way, we can filter or analyse results by language and trace whether we are retrieving original or translated text.

### 3.2 query é˜¶æ®µï¼šè¯­è¨€æ£€æµ‹ + æ£€ç´¢ç­–ç•¥

ä¸€ä¸ªåˆç†çš„æŸ¥è¯¢æµç¨‹æ˜¯ï¼š

1. æŸ¥è¯¢è¿›æ¥ â†’ **è¯­è¨€æ£€æµ‹**ï¼ˆå¯ä»¥ç”¨ langdetect / fastText / LLM è‡ªå·±åˆ¤æ–­ï¼‰
2. æ ¹æ®é€‰å®šæ–¹æ¡ˆï¼š

   * multilingual embeddingsï¼š

     * ç›´æ¥ç”¨åŸæ–‡ embedding â†’ åœ¨å…¨å±€ç´¢å¼•é‡Œæœ
   * translate-then-indexï¼š

     * æŠŠæŸ¥è¯¢ç¿»è¯‘æˆè‹±æ–‡ â†’ ç”¨è‹±æ–‡ embedding æœ

ç®€å•ä¼ªä»£ç ï¼š

```python
def answer_query(query, embed, vector_db, llm, strategy="multilingual"):
    lang = detect_language(query)  # "en", "sv", "de", ...
    
    if strategy == "translate_then_index" and lang != "en":
        query_for_embedding = translate_to_english(query)
    else:
        query_for_embedding = query

    q_vec = embed(query_for_embedding)
    results = vector_db.search(q_vec, top_k=10)

    # æ‹¼ context + è°ƒ LLM ç”Ÿæˆ
    context = "\n\n".join([r.payload["text"] for r in results])
    prompt = f"Question ({lang}): {query}\n\nContext:\n{context}\n\nAnswer:"
    return llm(prompt)
```

ä½ ä¸éœ€è¦å®Œæ•´èƒŒä»£ç ï¼Œåªè¦ä¼šå£è¿°è¿™ä¸ªé€»è¾‘å°±è¡Œã€‚

---

## å››ã€æŠ€æœ¯æ–‡æ¡£ + å¤šè¯­è¨€ï¼šè¦ç‰¹åˆ«æ³¨æ„å“ªäº›å‘ï¼Ÿ

è¿™æ˜¯åœ¨é¢è¯•é‡Œ**å¾ˆåŠ åˆ†**çš„ä¸€å—ï¼šè¯´æ˜ä½ çœŸçš„è€ƒè™‘è¿‡ä»–ä»¬çš„ domainã€‚

### 4.1 éƒ¨ä»¶ç¼–å· / å‹å·ï¼ˆpart numbersï¼‰

* `X-1234`, `AB-5678` è¿™ç§**è¯­è¨€æ— å…³**
* ä½† PDF è§£æ / OCR / tokenization å¯èƒ½æŠŠå®ƒä»¬åˆ‡æ–­æˆ–é”™è¯¯è¯†åˆ«
* è¦ä¿è¯ï¼š

  * ä¸åœ¨ chunking æ—¶æŠŠ part number åˆ†è£‚
  * åœ¨ schema é‡Œå•ç‹¬å­˜ä¸€ä¸ª `part_number` å­—æ®µï¼ˆç»“æ„åŒ–ï¼‰

ä½ å¯ä»¥è¯´ï¼š

> Part numbers are language-independent, so they should ideally be extracted as structured fields and not rely solely on free-text search.
> Chunking and parsing should be careful not to break part numbers across chunks.

### 4.2 å•ä½ / æ•°å€¼ / å®¹å·®

* æ¯”å¦‚ `5 mm`, `220 V`, `Â±0.5%` è¿™äº›ä¿¡æ¯ **æå…¶æ•æ„Ÿ**
* ç¿»è¯‘æ—¶å¯èƒ½è¢«é”™è¯¯å˜å½¢ï¼ˆå°¤å…¶æ˜¯å°æ•°ç‚¹ / åƒåˆ†ä½ / å•ä½ç¼©å†™ï¼‰
* å¤šè¯­è¨€ embedding é€šå¸¸å¯¹æ•°å­—æ¯”è¾ƒâ€œéº»æœ¨â€ï¼Œä½†ç»“æ„åŒ–å­˜å‚¨å¯ä»¥ç¼“è§£ï¼š

  * `spec_value`: 5
  * `spec_unit`: "mm"

ä½ å¯ä»¥è®²ï¼š

> For specs like dimensions or voltage, small errors are unacceptable.
> Where possible, we could extract these as structured fields and use them in metadata filters, instead of relying only on embeddings.

### 4.3 å¾·è¯­/ç‘å…¸è¯­å¤åˆè¯ & æœ¯è¯­

* å¾·è¯­æœ‰éå¸¸å¤šçš„**é•¿å¤åˆè¯**ï¼ˆä¸€ä¸ªè¯åŒ…å«å¾ˆå¤šæ„æ€ï¼‰
* ç‘å…¸è¯­ / å¾·è¯­é‡Œä¸“æœ‰åè¯å¯èƒ½å’Œè‹±æ–‡å®Œå…¨ä¸åŒç¿»è¯‘

ä½ å¯ä»¥è¯´ï¼š

> Multilingual embeddings can struggle with long German compound words or specialised technical terms.
> Thatâ€™s another reason why we might want to **combine** semantic search with structured metadata, especially for parts and specs.

---

## äº”ã€è¯„ä¼°ï¼šä½ æ€ä¹ˆåˆ¤æ–­å“ªç§å¤šè¯­è¨€æ–¹æ¡ˆæ›´å¥½ï¼Ÿ

è¿™æ˜¯ thesis çš„é‡ç‚¹ä¹‹ä¸€ã€‚ä½ å¯ä»¥æŠŠå›ç­”ç»“æ„è®¾è®¡å¥½ï¼š

> I would evaluate multilingual handling on **two levels**:
>
> 1. **Retrieval** quality
> 2. **End-to-end generation** quality

### 5.1 Retrieval å±‚é¢ï¼ˆæœ€å…³é”®ï¼‰

æ„å»ºä¸€ä¸ªè¯„ä¼°é›†ï¼š

* å¤šè¯­è¨€ queriesï¼ˆen/sv/deï¼‰
* æ¯ä¸ª query æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª **æ ‡æ³¨çš„ gold chunks**ï¼š

  * åŒ…å«æ­£ç¡® part çš„æè¿°ã€ä»·æ ¼ã€è§„æ ¼çš„ chunk

ç„¶åæ¯”è¾ƒä¸¤ä¸ªç³»ç»Ÿï¼š

* System Aï¼šmultilingual embeddingsï¼ˆåŸæ–‡ç›´æ¥ç´¢å¼•ï¼‰
* System Bï¼štranslate-then-indexï¼ˆç¿»è¯‘æˆè‹±æ–‡ç´¢å¼•ï¼‰

å¯¹æ¯ä¸ªç³»ç»Ÿï¼Œè®¡ç®—ï¼š

* **Recall@k**ï¼šåœ¨ top-k é‡Œæœ‰æ²¡æœ‰è‡³å°‘ä¸€ä¸ªæ­£ç¡® chunk
* **Precision@k**ï¼štop-k é‡Œæœ‰å¤šå°‘æ˜¯ç›¸å…³çš„
* **MRR** / nDCGï¼šæŸ¥çœ‹æ’åºè´¨é‡

ä½ å¯ä»¥è¯´ï¼š

> For each query, I would label the chunks that truly contain the correct part information, and then compare the multilingual vs translate-then-index setups using retrieval metrics such as Recall@k, Precision@k, and possibly MRR or nDCG.

### 5.2 Generation å±‚é¢ï¼ˆè¾…åŠ©éªŒè¯ï¼‰

å¯¹ä¸€éƒ¨åˆ† queries è·‘å®Œæ•´ RAG pipelineï¼Œæ£€æŸ¥ï¼š

* **ç­”æ¡ˆæ˜¯å¦åŒ…å«æ­£ç¡®çš„ part number**
* **ä»·æ ¼ã€å…³é”®è§„æ ¼æ˜¯å¦åŒ¹é… ground truthï¼ˆå…è®¸å°‘é‡å®¹å·®ï¼‰**

ä½ å¯ä»¥è¯´ï¼š

> On top of retrieval metrics, I would sample a subset of queries and run the full RAG pipeline, checking whether the generated answers:
>
> * mention the correct part number,
> * and match the reference price and key specs.
>
> This confirms that better retrieval actually translates into better end-to-end answers.

---

## å…­ã€é¢è¯• Q&A æ¨¡æ¿ï¼ˆDay 3 ç²¾åï¼‰

### Q1ï¼šHow would you handle multilingual documents in this RAG setup?

> Iâ€™d consider two main approaches.
>
> First, **multilingual embeddings**: keep documents in English, Swedish, and German, and use a multilingual encoder so that all texts live in a shared vector space. This naturally supports cross-lingual retrieval, e.g., an English query retrieving a German manual.
>
> Second, **translate-then-index**: translate non-English manuals into English offline, index the English versions, and possibly store the originals as metadata. Queries in other languages can also be translated to English before embedding.
>
> For this thesis, I would start with multilingual embeddings, since Weaviate supports this natively, and then build a translate-then-index baseline. Iâ€™d compare them using retrieval metrics on part-specific queries and see which handles our domain-specific terminology more robustly.

### Q2ï¼šWould you translate everything to English?

> I wouldnâ€™t assume that translation is always the best default, especially for technical content.
> Translation can introduce noise in part names, units, and tolerances.
>
> So Iâ€™d prefer to:
>
> * start with **multilingual embeddings on original texts**,
> * and treat **translation as a controlled experiment** or as an additional index,
>   rather than translating the entire corpus upfront without evaluation.

### Q3ï¼šWhat are the specific challenges of multilingual technical manuals?

> * Part numbers are language-independent but can be broken by poor parsing or chunking.
> * Specs and units must be exact, so translation or embedding errors can be costly.
> * German and Swedish technical terms and compound words may be hard for generic multilingual models.
>
> Thatâ€™s why Iâ€™d combine multilingual embeddings with **structure-aware chunking** and structured metadata like `part_number`, units, and language.

---

## ä¸ƒã€Day 3 å°ä»»åŠ¡ï¼ˆä½ å¯ä»¥ä¹‹åå‘ç»™æˆ‘æ”¹ï¼‰

1. ç”¨è‹±æ–‡å†™ä¸€æ®µï¼ˆ5â€“8 å¥ï¼‰å›ç­”ï¼š

   > â€œCompare multilingual embeddings with translate-then-index for multilingual RAG. What are the pros and cons of each, especially for technical documentation?â€

2. æƒ³ä¸€æƒ³ï¼š

   * å¦‚æœä½ è¦åœ¨è¿™ç¯‡ thesis é‡Œ**å…·ä½“è®¾è®¡ä¸€ä¸ªå¯¹æ¯”å®éªŒ**ï¼Œä½ ä¼šæ€ä¹ˆå†™ 3â€“4 è¡Œ â€œMethodâ€ æ®µè½ï¼Ÿ
   * æ¯”å¦‚ï¼š

     * Build two indices (multilingual vs translated English)
     * Evaluate on X queries in EN/SV/DE
     * Metrics: Recall@k, etc.

å†™å¥½ä¹‹åå‘ç»™æˆ‘ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ¶¦è‰²åˆ°â€œè®ºæ–‡ / é¢è¯•ç­”é¢˜æ°´å‡†â€ã€‚

---

å¦‚æœä½ è§‰å¾— Day 3 å¸æ”¶å¾—å·®ä¸å¤šäº†ï¼Œä¸‹ä¸€æ­¥æˆ‘ä»¬å¯ä»¥ Day 4ï¼š
**è¯„ä¼°æŒ‡æ ‡ & å®éªŒè®¾è®¡**â€”â€”è¿™ä¸€å—éå¸¸é€‚åˆä½ ç°åœ¨çš„ç ”ç©¶ç»éªŒï¼Œä¹Ÿå¾ˆå¥½å¾€â€œterm paper / thesis æ€ç»´â€ä¸Šé ã€‚
