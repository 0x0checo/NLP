1ã€**What is RAG?**

RAG is an architecture that combines retrieval with generation.
Instead of letting the LLM rely only on its internal parameters, the system retrieves the most relevant chunks from an external document store and injects them into the prompt so the answer becomes grounded and factual.
The goal is to reduce hallucinations and make the model respond based on real data.

RAG çš„å·¥ä½œæµç¨‹æ­£å¦‚å…¶åï¼Œåˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š

æ£€ç´¢ (Retrieval)ï¼š å½“ä½ æå‡ºä¸€ä¸ªé—®é¢˜ï¼ˆæ¯”å¦‚ï¼šâ€œå…¬å¸æœ€æ–°çš„æŠ¥é”€æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼‰ï¼Œç³»ç»Ÿä¸ä¼šç›´æ¥æŠŠé—®é¢˜ä¸¢ç»™å¤§æ¨¡å‹ï¼Œè€Œæ˜¯å…ˆå»ä½ çš„å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆæ¯”å¦‚å…¬å¸çš„æ–‡æ¡£æ•°æ®åº“ï¼‰ä¸­è¿›è¡Œæœç´¢ï¼Œæ‰¾åˆ°ä¸â€œæŠ¥é”€æ”¿ç­–â€æœ€ç›¸å…³çš„å‡ ä¸ªæ®µè½ã€‚

å¢å¼º (Augmentation)ï¼š ç³»ç»Ÿå°†ä½ åŸæ¥çš„é—®é¢˜ï¼ŒåŠ ä¸Šåˆšåˆšæ£€ç´¢åˆ°çš„é‚£äº›â€œç›¸å…³æ®µè½â€ï¼Œä¸€èµ·æ‰“åŒ…æˆä¸€ä¸ªæ–°çš„ã€æ›´ä¸°å¯Œçš„æç¤ºè¯ï¼ˆPromptï¼‰ã€‚

Prompt ç¤ºä¾‹ï¼š â€œç”¨æˆ·é—®ï¼šå…¬å¸æŠ¥é”€æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿè¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”ï¼š[æ£€ç´¢åˆ°çš„æ”¿ç­–æ–‡æ¡£ç‰‡æ®µ]...â€

ç”Ÿæˆ (Generation)ï¼š å¤§æ¨¡å‹æ¥æ”¶åˆ°è¿™ä¸ªå¢å¼ºåçš„æç¤ºè¯ï¼Œé˜…è¯»å‚è€ƒèµ„æ–™ï¼Œç„¶åç”Ÿæˆæœ€ç»ˆçš„ç­”æ¡ˆã€‚

2.**Chunking**
# Chunking Function: Principles and Strategies

## 1. What is Chunking?

Chunking is the process of splitting long documents into smaller, 
retrievable units ("chunks") that can be embedded, stored in a vector 
database, and provided to an LLM in a RAG pipeline.

A chunk is typically a short segment (e.g., 200â€“400 tokens) containing 
coherent information. Good chunking improves retrieval recall and 
grounds the LLMâ€™s output more reliably.

---

## 2. What Does a Chunking Function Do?

A chunking function takes raw text and produces a list of structured chunks:

**Input**
- raw text  
- chunking strategy  
- parameters: `max_tokens`, `overlap`  
- optional metadata (page, section, part_id, language)

**Output**
- list of chunks, each containing:
  - text  
  - metadata  



# RAG Chunking Strategies

This document outlines the core chunking techniques used in Retrieval-Augmented Generation (RAG) systems. Choosing the right strategy is a critical trade-off that directly impacts **Retrieval Recall** and **Generation Precision**.

## 1. Fixed-size Chunking
This is the baseline approach, often used as a starting point.

* **Principle:** Split text into chunks of a fixed size $N$ (characters or tokens), disregarding content structure.
* **Mechanism:** Usually paired with **Overlap**.
    * *Example:* Chunk Size = 500, Overlap = 50.
    * Chunk 1: `[0:500]`, Chunk 2: `[450:950]`.
* **Pros & Cons:**
    * âœ… **Pros:** Computationally cheap; easy to implement; requires no NLP models.
    * âŒ **Cons:** **Semantic Discontinuity**. It blindly cuts through sentences, names, or logical groupings, potentially losing context (though overlap mitigates this slightly).

## 2. Sliding Window Chunking
A technique often combined with fixed-size chunking to enhance context window retrieval.

* **Principle:** Instead of simple overlap, this approach uses a sliding window to capture granular context or retrieval-time expansion.
* **Granularity:**
    * *Chunk 1:* Sentence A + Sentence B + Sentence C
    * *Chunk 2:* Sentence B + Sentence C + Sentence D
* **Core Value:** **Eliminates Boundary Effects**. It ensures that no critical information is lost simply because it fell on a "cut" line, as every data point will eventually appear in the center of a window.

## 3. Structure-aware Chunking (Recursive)
Also known as **Recursive Character Chunking**, this is currently the **industry standard** for processing structured documents (PDF, Markdown, HTML).

* **Principle:** Respects the document's native structure (Headers, Paragraphs, Lists, Code Blocks) rather than splitting by arbitrary character counts.
* **Workflow:**
    1.  **Parse:** Identify separators (e.g., Markdown `#`, `##` or HTML `<div>`).
    2.  **Recursive Split:** Attempt to split by the largest logical unit (e.g., Chapter). If the chunk is still too large for the token limit, recurse down to the next level (e.g., Paragraph).
    3.  **Integrity:** Ensures tables and code blocks remain intact.
* **Core Value:** **High Semantic Cohesion**. Content within a chunk is logically related, and metadata (headers) can be preserved for better retrieval.

## 4. Semantic Chunking
An advanced, **SOTA (State of the Art)** technique that prioritizes meaning over formatting.

* **Principle:** Splits text based on shifts in semantic meaning rather than physical delimiters.
* **Algorithm:**
    1.  **Sentence Embeddings:** Generate vector embeddings for individual sentences.
    2.  **Similarity Check:** Calculate Cosine Similarity between adjacent sentences.
    3.  **Threshold Split:** If similarity is high, merge sentences. If similarity drops below a threshold (indicating a topic change), create a split.
* **Core Value:** **High Signal-to-Noise Ratio**. Each chunk represents a distinct, complete semantic thought, which is crucial for answering complex questions.

## 5. Multilingual Chunking
Essential for globalized applications to handle language density differences.

* **The Problem:** "Length" is defined differently across languages.
    * *Tokenizer differences:* English relies on spaces; CJK (Chinese/Japanese/Korean) languages are dense and lack spacing.
    * *The Trap:* A 500-character limit is a paragraph in English but could be a short essay in Chinese. Using character counts leads to massive chunks in CJK, diluting retrieval accuracy.
* **Solution:**
    * Use **Language-specific splitters** (e.g., NLTK, SpaCy).
    * **Token-based Counting:** Standardize length using the LLM's tokenizer (e.g., `tiktoken`) rather than raw character counts to ensure consistent information density.

---

## âš¡ï¸ Summary & Comparison

| Strategy | Core Logic | Best Use Case | Cost |
| :--- | :--- | :--- | :--- |
| **Fixed-size** | Hard split by length | Plain text, MVP / Baseline testing | ğŸŸ¢ Low |
| **Sliding Window** | High overlap | High recall requirements; preventing boundary loss | ğŸŸ¡ Medium |
| **Structure-aware** | **Document Syntax** | **Standard RAG** (Markdown/PDF/Code) | ğŸŸ¡ Medium |
| **Semantic** | **Meaning/Topic** | Advanced RAG; High precision needs | ğŸ”´ High (GPU) |
| **Multilingual** | Token/Language specific | Multi-language support (CJK mixed with En) | ğŸŸ¡ Medium |

### ğŸ’¡ Recommendation
* **Start with:** **Structure-aware (Recursive)** chunking. It offers the best balance of performance and cost.
* **Upgrade to:** **Semantic Chunking** only if you have unstructured text with shifting topics and require maximum accuracy.
