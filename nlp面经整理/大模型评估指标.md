**1.混淆矩阵有何作用？分类任务中有哪几个常规的指标？**

很好，这里我们分两部分回答：

---

## 1. 混淆矩阵的作用

混淆矩阵（Confusion Matrix）是 **分类模型预测结果的总结表**，它能直观展示：

* 模型的 **正确预测** 和 **错误预测** 情况
* 错误主要发生在哪些类别之间（例如把“猫”错分成“狗”）

👉 作用：

1. **全面评估模型性能**（不仅看准确率，还能看误差分布）
2. **找出分类偏差**（哪些类容易混淆）
3. **为指标计算提供基础**（准确率、精确率、召回率、F1 都来自混淆矩阵）

以二分类为例（正类 = 1，负类 = 0）：

|              | 预测正类 (1) | 预测负类 (0) |
| ------------ | -------- | -------- |
| **真实正类 (1)** | TP（真正例）  | FN（假负例）  |
| **真实负类 (0)** | FP（假正例）  | TN（真负例）  |

---

## 2. 分类任务中的常规指标

1. **准确率 (Accuracy)**

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
$$

表示整体预测正确的比例。
⚠️ 缺点：样本不平衡时（正负类差距大），准确率可能误导。

---

2. **精确率 (Precision)**

$$
Precision = \frac{TP}{TP + FP}
$$

表示预测为正类的样本中，真正正类的比例。
👉 关注 **预测结果的可靠性**（例如垃圾邮件检测中，预测“垃圾”的邮件里有多少是真的垃圾？）。

---

3. **召回率 (Recall, Sensitivity)**

$$
Recall = \frac{TP}{TP + FN}
$$

表示所有真实正类中，被正确识别出来的比例。
👉 关注 **漏检情况**（例如癌症检测中，能识别出多少真实患者？）。

---

4. **F1 值 (F1-score)**

$$
F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
$$

是 **精确率和召回率的调和平均**，平衡两者。

---

5. **特异度 (Specificity)**

$$
Specificity = \frac{TN}{TN + FP}
$$

表示负类中被正确识别的比例。
👉 关注 **误报情况**。

---

6. **AUC-ROC (Area Under Curve - Receiver Operating Characteristic)**

* ROC 曲线横轴是 FPR（假正率），纵轴是 TPR（真正率 = Recall）。
* AUC 表示曲线下的面积，越接近 1，模型区分能力越强。
  👉 适合评估样本不均衡的数据集。

---

✅ **总结**：

* 混淆矩阵 → 提供分类结果全貌。
* 常规指标：**准确率、精确率、召回率、F1、特异度、AUC**。
* 不同任务关注点不同：

  * 欠检严重的场景（如医疗） → 召回率
  * 误报代价高的场景（如垃圾邮件） → 精确率
  * 综合考虑 → F1 / AUC

---

