{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg1/p66cY9sI2w8EiLiSFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0x0checo/NLP/blob/main/%E4%B8%AD%E6%96%87%E7%BD%91%E8%B4%AD%E6%83%85%E6%84%9F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2TFdhrs4UHIE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gFOETNzaV_SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "UoMzrFHnUimZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.加载数据集\n",
        "dataset = load_dataset(\"lansinuote/ChnSentiCorp\", download_mode=\"force_redownload\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4hDE8L6NVB8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "id": "NQOEargtlvs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.加载分词器\n",
        "model_name = \"google-bert/bert-base-chinese\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QqIgu0jrmCIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 定义数据预处理函数\n",
        "def preprocess_data(data):\n",
        "    encoding = tokenizer(\n",
        "        data['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "_7G1_HDxmTpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.对数据集进行预处理\n",
        "encoded_dataset = dataset.map(preprocess_data, batched=True)"
      ],
      "metadata": {
        "id": "5-CX5HjIn_DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "功能：map 方法遍历数据集中的所有样本（或批量样本），并对每个样本应用用户定义的函数（preprocess_function），以转换、增强或预处理数据。处理后的结果会生成一个新的数据集（encoded_dataset）。"
      ],
      "metadata": {
        "id": "X-K0lVxdo6zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_dataset)"
      ],
      "metadata": {
        "id": "YQE5ncjCosro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.转换数据格式（Hugging Face dataset -> PyTorch dataset）\n",
        "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "print(encoded_dataset['train'][0])"
      ],
      "metadata": {
        "id": "gf1TjsJspXUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoded_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]) 是一个关键的预处理步骤，用于将 Hugging Face 数据集的输出格式转换为 PyTorch 张量，并限制返回的列为模型输入所需的字段（input_ids、attention_mask、label）。\n",
        "\n",
        "set_format 方法用于设置数据集的输出格式，控制数据集在被访问时返回的数据类型和结构。它不会修改数据的底层存储，而是改变数据被提取时的表示形式。"
      ],
      "metadata": {
        "id": "280YoyXwqY40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.加载模型\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-uK8jFvLqh7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.定义数据加载方式\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "HexgfLTuq_Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) 定义了一个数据整理器，用于在批处理数据时动态填充变长序列（如 input_ids 和 attention_mask），以满足 Transformer 模型的输入要求。它通过与分词器协作，自动处理填充和注意力掩码生成，确保批次张量形状一致，同时优化内存和计算效率。这一步骤是 Hugging Face Trainer 和 PyTorch DataLoader 的关键组成部分，简化了 NLP 任务的数据准备流程。"
      ],
      "metadata": {
        "id": "hAWbceqksEsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.评估函数\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    return {'accuracy': accuracy, \"precision\": precision, 'recall': recall, 'f1_score': f1}"
      ],
      "metadata": {
        "id": "Cc6IM8lpsHBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.设置训练参数\n",
        "\"\"\"\n",
        "功能：TrainingArguments 是一个参数容器，用于指定训练过程中的超参数、策略和输出设置。\n",
        "它为 Trainer 类提供配置，控制训练、评估、模型保存、日志记录等行为。\n",
        "用途：通过设置 TrainingArguments，用户可以自定义训练流程，例如指定训练轮数、批次大小、\n",
        "优化器参数、评估频率等，适配不同的任务（如文本分类、机器翻译）和计算资源。\n",
        "\"\"\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./out/bert_chinese_sentiment\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./out/logs\",\n",
        "    logging_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "id": "K7xwBsXB3jiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.定义Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "7xR2nJ2hM4Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ],
      "metadata": {
        "id": "j-vYa1yAPkxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.启动训练\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "n6CDCHgaN1u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12.评估模型\n",
        "results = trainer.evaluate()\n",
        "print(results)"
      ],
      "metadata": {
        "id": "nERsnfLTQg9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"13.保存模型\n",
        "model.save_pretrained(\"./out/bert_chinese_sentiment\")\n",
        "tokenizer.save_pretrained(\"./out/bert_chinese_sentiment\")\n",
        "os.listdir('/content/out/bert_chinese_sentiment/')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ymWKk6sIQ1-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}